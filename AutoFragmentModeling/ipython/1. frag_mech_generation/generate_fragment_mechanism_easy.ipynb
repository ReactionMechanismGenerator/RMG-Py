{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Flow of Fragment Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "- load text fragment mechanism (text based: mech and smiles)\n",
    "\n",
    "- create fragments and fragment reactions (from smiles, check isomorphic duplicate, add reaction_repr for fragment reaction)\n",
    "\n",
    "- get thermo and kinetics\n",
    "\n",
    "Input:\n",
    "\n",
    "- text fragment mechanism and smiles dict\n",
    "\n",
    "Output:\n",
    "\n",
    "- chemkin file for fragment mechanism\n",
    "\n",
    "**IMPORTANT**: USE RMG-Py frag_kinetics_gen_new branch, RMG-dabase frag_kinetics_gen_new branch, rmg_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmgpy import settings\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "from rmgpy.kinetics import KineticsData\n",
    "from rmgpy.rmg.model import getFamilyLibraryObject\n",
    "from rmgpy.data.kinetics.family import TemplateReaction\n",
    "from rmgpy.data.kinetics.depository import DepositoryReaction\n",
    "from rmgpy.data.kinetics.common import find_degenerate_reactions\n",
    "from rmgpy.chemkin import saveChemkinFile, saveSpeciesDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import afm\n",
    "import afm.fragment\n",
    "import afm.reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frag_mech(frag_mech_path):\n",
    "\n",
    "\treaction_string_dict = {}\n",
    "\tcurrent_family = ''\n",
    "\twith open(frag_mech_path) as f_in:\n",
    "\t\tfor line in f_in:\n",
    "\t\t\tif line.startswith('#') and ':' in line:\n",
    "\t\t\t\t_, current_family = [token.strip() for token in line.split(':')]\n",
    "\t\t\telif line.strip() and not line.startswith('#'):\n",
    "\t\t\t\treaction_string = line.strip()\n",
    "\t\t\t\tif current_family not in reaction_string_dict:\n",
    "\t\t\t\t\treaction_string_dict[current_family] = [reaction_string]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treaction_string_dict[current_family].append(reaction_string)\n",
    "\n",
    "\treturn reaction_string_dict\n",
    "\n",
    "def parse_reaction_string(reaction_string):\n",
    "\n",
    "\treactant_side, product_side = [token.strip() for token in reaction_string.split('==')]\n",
    "\treactant_strings = [token.strip() for token in reactant_side.split('+')]\n",
    "\tproduct_strings = [token.strip() for token in product_side.split('+')]\n",
    "\n",
    "\treturn reactant_strings, product_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load text-format fragment mech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'one-sided'\n",
    "afm_base = os.path.dirname(afm.__path__[0])\n",
    "working_dir = os.path.join(afm_base, 'examples', '2mobenzene', job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RMG database to create reactions\n",
    "database = RMGDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database.load(\n",
    "    path = settings['database.directory'], \n",
    "    thermoLibraries = ['primaryThermoLibrary'], # can add others if necessary\n",
    "    kineticsFamilies = 'all', \n",
    "    reactionLibraries = [], \n",
    "    kineticsDepositories = ''\n",
    ")\n",
    "thermodb = database.thermo\n",
    "# Add training reactions\n",
    "for family in database.kinetics.families.values():\n",
    "    family.addKineticsRulesFromTrainingSet(thermoDatabase=thermodb)\n",
    "# average up all the kinetics rules\n",
    "for family in database.kinetics.families.values():\n",
    "    family.fillKineticsRulesByAveragingUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fragment from smiles-like string\n",
    "fragment_smiles_filepath = os.path.join(working_dir, 'fragment_smiles.txt')\n",
    "\n",
    "fragments = []\n",
    "with open(fragment_smiles_filepath) as f_in:\n",
    "    for line in f_in:\n",
    "        if line.strip() and not line.startswith('#') and ':' in line:\n",
    "            label, smiles = [token.strip() for token in line.split(\":\")]\n",
    "            frag = afm.fragment.Fragment(label=label).from_SMILES_like_string(smiles)\n",
    "            frag.assign_representative_species()\n",
    "            frag.species_repr.label = label\n",
    "            for prev_frag in fragments:\n",
    "                if frag.isIsomorphic(prev_frag):\n",
    "                    raise Exception('Isomorphic duplicate found: {0} and {1}'.format(label, prev_frag.label))\n",
    "            fragments.append(frag)\n",
    "\n",
    "# construct label-key fragment dictionary\n",
    "fragment_dict = {}\n",
    "for frag0 in fragments:\n",
    "    if frag0.label not in fragment_dict:\n",
    "        fragment_dict[frag0.label] = frag0\n",
    "        \n",
    "    else:\n",
    "        raise Exception('Fragment with duplicated labels found: {0}'.format(frag0.label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put aromatic isomer in front of species.molecule\n",
    "# 'cause that's the isomer we want to react\n",
    "for frag in fragments:\n",
    "    species = frag.species_repr\n",
    "    species.generateResonanceIsomers()\n",
    "    for mol in species.molecule:\n",
    "        if mol.isAromatic():\n",
    "            species.molecule = [mol]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_Addition_MultipleBond...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:02<00:00,  5.80it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing H_Abstraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [03:36<00:00,  1.61s/it]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_Recombination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Disproportionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# load fragment mech in text\n",
    "fragment_mech_filepath = os.path.join(working_dir, 'frag_mech.txt')\n",
    "\n",
    "reaction_string_dict = read_frag_mech(fragment_mech_filepath)\n",
    "\n",
    "# generate reactions\n",
    "fragment_rxns = []\n",
    "\n",
    "for family_label in reaction_string_dict:\n",
    "    # parse reaction strings\n",
    "    print \"Processing {0}...\".format(family_label)\n",
    "    for reaction_string in tqdm(reaction_string_dict[family_label]):\n",
    "        reactant_strings, product_strings = parse_reaction_string(reaction_string)\n",
    "        \n",
    "\n",
    "        reactants = [fragment_dict[reactant_string].species_repr for reactant_string in reactant_strings]\n",
    "        \n",
    "        products = [fragment_dict[product_string].species_repr.molecule[0] for product_string in product_strings]\n",
    "        \n",
    "        for idx, reactant in enumerate(reactants):\n",
    "            for mol in reactant.molecule:\n",
    "                mol.props['label'] = reactant_strings[idx]\n",
    "        \n",
    "        for idx, product in enumerate(products):\n",
    "            product.props['label'] = product_strings[idx]\n",
    "        # this script requires reactants to be a list of Species objects\n",
    "        # products to be a list of Molecule objects.\n",
    "        # returned rxns have reactants and products in Species type\n",
    "        new_rxns = database.kinetics.generate_reactions_from_families(reactants=reactants, \n",
    "                                                                      products=products, \n",
    "                                                                      only_families=[family_label],\n",
    "                                                                     resonance=True)\n",
    "\n",
    "        if len(new_rxns) != 1:\n",
    "            print reaction_string + family_label\n",
    "\n",
    "            raise Exception('Non-unique reaction is generated with {0}'.format(reaction_string))\n",
    "        \n",
    "        # create fragment reactions\n",
    "        rxn = new_rxns[0]\n",
    "        \n",
    "        fragrxn = afm.reaction.FragmentReaction(index=-1,\n",
    "                                    reversible=True,\n",
    "                                    family=rxn.family,\n",
    "                                    reaction_repr=rxn)\n",
    "\n",
    "        fragment_rxns.append(fragrxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. get thermo and kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmgpy.data.rmg import getDB\n",
    "from rmgpy.thermo.thermoengine import processThermoData\n",
    "from rmgpy.thermo import NASA\n",
    "import rmgpy.constants as constants\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [01:01<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "thermodb = getDB('thermo')\n",
    "# calculate thermo for each species\n",
    "for fragrxn in tqdm(fragment_rxns):\n",
    "    rxn0 = fragrxn.reaction_repr\n",
    "    for spe in rxn0.reactants + rxn0.products:\n",
    "        thermo0 = thermodb.getThermoData(spe)\n",
    "        if spe.label in ['RCCCCR', 'LCCCCR', 'LCCCCL']:\n",
    "            thermo0.S298.value_si += constants.R * math.log(2)\n",
    "        spe.thermo = processThermoData(spe, thermo0, NASA)\n",
    "    \n",
    "    family = getFamilyLibraryObject(rxn0.family)\n",
    "    # Get the kinetics for the reaction\n",
    "    kinetics, source, entry, isForward = family.getKinetics(rxn0, \\\n",
    "                                    templateLabels=rxn0.template, degeneracy=rxn0.degeneracy, \\\n",
    "                                    estimator='rate rules', returnAllKinetics=False)\n",
    "    rxn0.kinetics = kinetics\n",
    "\n",
    "    if not isForward:\n",
    "        rxn0.reactants, rxn0.products = rxn0.products, rxn0.reactants\n",
    "        rxn0.pairs = [(p,r) for r,p in rxn0.pairs]\n",
    "    \n",
    "    # convert KineticsData to Arrhenius forms\n",
    "    if isinstance(rxn0.kinetics, KineticsData):\n",
    "        rxn0.kinetics = rxn0.kinetics.toArrhenius()\n",
    "    #  correct barrier heights of estimated kinetics\n",
    "    if isinstance(rxn0,TemplateReaction) or isinstance(rxn0,DepositoryReaction): # i.e. not LibraryReaction\n",
    "        rxn0.fixBarrierHeight() # also converts ArrheniusEP to Arrhenius.\n",
    "    \n",
    "    fragrxts = [fragment_dict[rxt.label] for rxt in rxn0.reactants]\n",
    "    fragprds = [fragment_dict[prd.label] for prd in rxn0.products]\n",
    "    fragpairs = [(fragment_dict[p0.label],fragment_dict[p1.label]) for p0,p1 in rxn0.pairs]\n",
    "    \n",
    "    fragrxn.reactants=fragrxts\n",
    "    fragrxn.products=fragprds\n",
    "    fragrxn.pairs=fragpairs\n",
    "    fragrxn.kinetics=rxn0.kinetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 correct entropy for certain fragments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCCCCR\n",
      "-135.498883047\n"
     ]
    }
   ],
   "source": [
    "for frag in fragments:\n",
    "    spe = frag.species_repr\n",
    "    thermo0 = thermodb.getThermoData(spe)\n",
    "    if spe.label in ['RCCCCR', 'LCCCCR', 'LCCCCL']:\n",
    "        thermo0.S298.value_si += constants.R * math.log(2)\n",
    "    \n",
    "    spe.thermo = processThermoData(spe, thermo0, NASA)\n",
    "    if spe.label in ['RCCCCR', 'LCCCCR', 'LCCCCL']:\n",
    "        print spe.label\n",
    "        print spe.getFreeEnergy(670)/4184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 correct kinetics for reactions with certain fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:00<00:00, 154790.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for fragrxn in tqdm(fragment_rxns):\n",
    "    rxn0 = fragrxn.reaction_repr\n",
    "    if rxn0.family in ['R_Recombination', 'H_Abstraction', 'R_Addition_MultipleBond']:\n",
    "        for spe in rxn0.reactants + rxn0.products:\n",
    "            if spe.label in ['RCC*CCR', 'LCC*CCR', 'LCC*CCL']:\n",
    "                rxn0.kinetics.changeRate(4)\n",
    "        \n",
    "        fragrxn.kinetics=rxn0.kinetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. save in chemkin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_list = []\n",
    "for frag in fragments:\n",
    "    species = frag.species_repr\n",
    "    species_list.append(species)\n",
    "len(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_list = []\n",
    "for fragrxn in fragment_rxns:\n",
    "    rxn = fragrxn.reaction_repr\n",
    "    reaction_list.append(rxn)\n",
    "len(reaction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n",
      "WARNING:root:Species label is longer than 15 characters and will break CHEMKIN 2.0\n"
     ]
    }
   ],
   "source": [
    "# dump chemkin files\n",
    "chemkin_path = os.path.join(working_dir, 'chem_annotated.inp')\n",
    "dictionaryPath = os.path.join(working_dir, 'species_dictionary.txt')\n",
    "saveChemkinFile(chemkin_path, species_list, reaction_list)\n",
    "saveSpeciesDictionary(dictionaryPath, species_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. correct atom count in chemkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_atom_count(tokens, parts, R_count):\n",
    "\n",
    "\t# remove R_count*2 C and R_count*5 H\n",
    "\tstring = ''\n",
    "\tif R_count == 0:\n",
    "\t\treturn 'G'.join(parts)\n",
    "\telse:\n",
    "\t\tH_count = int(tokens[2].split('C')[0])\n",
    "\t\tH_count_update = H_count - 5*R_count\n",
    "\n",
    "\t\tC_count = int(tokens[3])\n",
    "\t\tC_count_update = C_count - 2*R_count\n",
    "\n",
    "\t\ttokens = tokens[:2] + [str(H_count_update)+'C'] + [C_count_update]\n",
    "\n",
    "\t\t# Line 1\n",
    "\t\tstring += '{0:<16}        '.format(tokens[0])\n",
    "\n",
    "\t\tstring += '{0!s:<2}{1:>3d}'.format('H', H_count_update)\n",
    "\t\tstring += '{0!s:<2}{1:>3d}'.format('C', C_count_update)\n",
    "\t\tstring += '     ' * (4 - 2)\n",
    "\t\tstring += 'G' + parts[1]\n",
    "\t\treturn string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_chemkin_path = os.path.join(working_dir, 'chem_annotated.inp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = ''\n",
    "with open(chemkin_path) as f_in:\n",
    "    readThermo = False\n",
    "    for line in f_in:\n",
    "        if line.startswith('THERM ALL'):\n",
    "            readThermo = True\n",
    "\n",
    "        if not readThermo: \n",
    "            output_string += line\n",
    "            continue\n",
    "\n",
    "        if line.startswith('!'): \n",
    "            output_string += line\n",
    "            continue\n",
    "\n",
    "        if 'G' in line and '1' in line:\n",
    "            parts = [part for part in line.split('G')]\n",
    "            tokens = [token.strip() for token in parts[0].split()]\n",
    "\n",
    "            species_label = tokens[0]\n",
    "            R_count = species_label.count('R')\n",
    "            L_count = species_label.count('L')\n",
    "\n",
    "            updated_line = update_atom_count(tokens, parts, R_count+L_count)\n",
    "\n",
    "            output_string += updated_line\n",
    "\n",
    "        else:\n",
    "            output_string += line\n",
    "\n",
    "with open(corrected_chemkin_path, 'w') as f_out:\n",
    "\tf_out.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. add pseudo reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
